{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2FHz1--3c9f"
      },
      "outputs": [],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd signature_verification"
      ],
      "metadata": {
        "id": "zJ0uf47u3l-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls dataset2/1/"
      ],
      "metadata": {
        "id": "-Eqr7mdI3rTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import time\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate, Dropout, AveragePooling2D\n",
        "from keras.models import Model\n",
        "\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.layers.core import Lambda, Flatten, Dense\n",
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "from tensorflow.keras.layers import Layer \n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.keras.callbacks import TensorBoard\n"
      ],
      "metadata": {
        "id": "vnvCXRzY3tYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"dataset2/\"\n",
        "\n",
        "\n",
        "# Get the list of all directories and sort them\n",
        "dir_list = next(os.walk(path))[1]\n",
        "dir_list.sort()"
      ],
      "metadata": {
        "id": "g4rWHdnI3tmc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"dataset2/\"\n",
        "\n",
        "\n",
        "# Get the list of all directories and sort them\n",
        "dir_list = next(os.walk(path))[1]\n",
        "dir_list.sort()\n",
        "\n",
        "\n",
        "orig_groups, forg_groups = [], []\n",
        "\n",
        "for directory in dir_list:\n",
        "    images = next(os.walk(path+directory))[2]\n",
        "                 \n",
        "    images.sort()\n",
        "    images = [ path + directory+'/'+ x for x in images]\n",
        "    forg_groups.append(images[:24]) # First 30 signatures in each folder are forrged\n",
        "    orig_groups.append(images[24:])\n",
        "    \n",
        "    \n",
        "    \n",
        "# Quick check to confirm we have data of all the 160 individuals\n",
        "len(orig_groups), len(forg_groups)\n",
        "\n",
        "\n",
        "\n",
        "orig_lengths = [len(x) for x in orig_groups]\n",
        "forg_lengths = [len(x) for x in forg_groups]\n",
        "\n",
        "\n",
        "\n",
        "# Quick check to confirm that there are 24 Genuine signatures for each individual\n",
        "print(orig_lengths)\n",
        "print(forg_lengths)\n",
        "\n",
        "orig_train, orig_val, orig_test = orig_groups[:40], orig_groups[40:50], orig_groups[50:]\n",
        "forg_train, forg_val, forg_test = forg_groups[:40], forg_groups[40:50], forg_groups[50:]\n",
        "\n",
        "\n",
        "img_h, img_w = 160, 160\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GiyD_bdG3tp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_sample_signature():\n",
        "    '''Function to randomly select a signature from train set and\n",
        "    print two genuine copies and one forged copy'''\n",
        "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize = (10, 10))\n",
        "    k = np.random.randint(len(orig_train))\n",
        "    orig_img_names = random.sample(orig_train[k], 2)\n",
        "    forg_img_name = random.sample(forg_train[k], 1)\n",
        "    orig_img1 = cv2.imread(orig_img_names[0], 0)\n",
        "    orig_img2 = cv2.imread(orig_img_names[1], 0)\n",
        "    forg_img = plt.imread(forg_img_name[0], 0)\n",
        "    orig_img1 = cv2.resize(orig_img1, (img_w, img_h))\n",
        "    orig_img2 = cv2.resize(orig_img2, (img_w, img_h))\n",
        "    forg_img = cv2.resize(forg_img, (img_w, img_h))\n",
        "\n",
        "    ax1.imshow(orig_img1, cmap = 'gray')\n",
        "    ax2.imshow(orig_img2, cmap = 'gray')\n",
        "    ax3.imshow(forg_img, cmap = 'gray')\n",
        "\n",
        "    ax1.set_title('Genuine Copy')\n",
        "    ax1.axis('off')\n",
        "    ax2.set_title('Genuine Copy')\n",
        "    ax2.axis('off')\n",
        "    ax3.set_title('Forged Copy')\n",
        "    ax3.axis('off')\n",
        "    \n",
        "    \n",
        "visualize_sample_signature()\n",
        "visualize_sample_signature()\n",
        "visualize_sample_signature()\n",
        "visualize_sample_signature()"
      ],
      "metadata": {
        "id": "kDkQ2RH33ttM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forg_groups"
      ],
      "metadata": {
        "id": "KiaYRqtW3tv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_pairs = []\n",
        "forg_pairs = []\n",
        "gen_gen_labels = []\n",
        "gen_for_labels = []\n",
        "all_pairs = []\n",
        "all_labels = []\n",
        "\n",
        "# Here we create pairs of Genuine-Genuine image names and Genuine-Forged image names\n",
        "# For every person we have 24 genuine signatures, hence we have \n",
        "# 24 choose 2 = 276 Genuine-Genuine image pairs for one person.\n",
        "# To make Genuine-Forged pairs, we pair every Genuine signature of a person\n",
        "# with 12 randomly sampled Forged signatures of the same person.\n",
        "# Thus we make 24 * 12 = 300 Genuine-Forged image pairs for one person.\n",
        "# In all we have 120 person's data in the training data.\n",
        "# Total no. of Genuine-Genuine pairs = 120 * 276 = 33120\n",
        "# Total number of Genuine-Forged pairs = 120 * 300 = 36000\n",
        "# Total no. of data points = 33120 + 36000 = 69120\n",
        "for orig, forg in zip(orig_groups, forg_groups):\n",
        "\n",
        "    orig_pairs.extend(list(itertools.combinations(orig, 2)))\n",
        "    \n",
        "    for i in range(len(forg)):\n",
        "        forg_pairs.extend(list(itertools.product(orig[i:i+1], random.sample(forg, 12))))\n",
        "        \n",
        "print(orig_pairs)"
      ],
      "metadata": {
        "id": "_F1w5qI33ty0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig"
      ],
      "metadata": {
        "id": "woXZRBWL3t1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forg"
      ],
      "metadata": {
        "id": "X4y8_0OD4EFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1J9deq7z4EIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "path = \"dataset/\"\n",
        "path2=\"dataset2/\"\n",
        "#options = tf.data.Options()\n",
        "#options.experimental_distribute.auto_shard_policy = AutoShardPolicy.OFF\n",
        "# Get the list of all directories and sort them\n",
        "dir_list = next(os.walk(path))[1]\n",
        "dir_list.sort()\n",
        "dir_list2 = next(os.walk(path2))[1]\n",
        "dir_list2.sort()\n",
        "\n",
        "orig_groups, forg_groups = [], []\n",
        "\n",
        "##4000 dir\n",
        "for directory in dir_list:\n",
        "   \n",
        "    images = next(os.walk(path+directory))[2]\n",
        "    images.sort()\n",
        "    images = [ path + directory+'/'+ x for x in images]\n",
        "    orig_groups.append(images[96:]) # First 30 signatures in each folder are forrged\n",
        "    forg_groups.append(images[:96])\n",
        "    \n",
        "print(len(orig_groups))\n",
        "print(len(forg_groups))\n",
        "##55 dir\n",
        "for directory2 in dir_list2:\n",
        "    images = next(os.walk(path2+directory2))[2]\n",
        "    images.sort()\n",
        "    images = [ path2 + directory2+'/'+ x for x in images]\n",
        "    forg_groups.append(images[:24]) # First 30 signatures in each folder are forrged\n",
        "    orig_groups.append(images[24:48])\n",
        "\n",
        "    \n",
        "# Quick check to confirm we have data of all the 160 individuals\n",
        "print(len(orig_groups))\n",
        "print(len(forg_groups))\n",
        "\n",
        "\n",
        "orig_lengths = [len(x) for x in orig_groups]\n",
        "forg_lengths = [len(x) for x in forg_groups]\n",
        "\n",
        "\n",
        "\n",
        "# Quick check to confirm that there are 24 Genuine signatures for each individual\n",
        "print(len(orig_lengths))\n",
        "print(len(forg_lengths))\n",
        "orig_train, orig_val, orig_test = orig_groups[:55], orig_groups[55:75], orig_groups[75:80]\n",
        "forg_train, forg_val, forg_test = forg_groups[:55], forg_groups[55:75], forg_groups[75:80]\n",
        "\n",
        "\n",
        "img_h, img_w = 160,160"
      ],
      "metadata": {
        "id": "8EGpYwqE4ELk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_pairs = []\n",
        "forg_pairs = []\n",
        "gen_gen_labels = []\n",
        "gen_for_labels = []\n",
        "all_pairs = []\n",
        "all_labels = []\n",
        "\n",
        "# Here we create pairs of Genuine-Genuine image names and Genuine-Forged image names\n",
        "# For every person we have 24 genuine signatures, hence we have \n",
        "# 24 choose 2 = 276 Genuine-Genuine image pairs for one person.\n",
        "# To make Genuine-Forged pairs, we pair every Genuine signature of a person\n",
        "# with 12 randomly sampled Forged signatures of the same person.\n",
        "# Thus we make 24 * 12 = 300 Genuine-Forged image pairs for one person.\n",
        "# In all we have 120 person's data in the training data.\n",
        "# Total no. of Genuine-Genuine pairs = 120 * 276 = 33120\n",
        "# Total number of Genuine-Forged pairs = 120 * 300 = 36000\n",
        "# Total no. of data points = 33120 + 36000 = 69120\n",
        "for orig, forg in zip(orig_groups, forg_groups):    \n",
        "    orig_pairs.extend(list(itertools.combinations(orig, 2)))\n",
        "    for i in orig:\n",
        "        for j in forg:\n",
        "            forg_pairs.append((i,j))\n",
        "        \n",
        "print(len(orig_pairs))\n",
        "print(\"_____\")\n",
        "print(len(forg_pairs))\n",
        "print(orig_pairs[:20])\n",
        "# p=orig_pairs + forg_pairs\n",
        "# print(p)\n",
        "gen_gen_labels = [1]*len(orig_pairs)\n",
        "gen_for_labels = [0]*len(forg_pairs)\n",
        "\n",
        "# Concatenate all the pairs together along with their labels and shuffle them\n",
        "all_pairs = orig_pairs + forg_pairs\n",
        "all_labels = gen_gen_labels + gen_for_labels\n",
        "# print(all_pairs)\n",
        "\n",
        "# del orig_pairs, forg_pairs, gen_gen_labels, gen_for_labels\n",
        "all_pairs, all_labels = shuffle(all_pairs, all_labels)\n",
        "\n",
        "# for i in range(0,12000):\n",
        "#     if all_labels[i]==1:\n",
        "#         print(all_pairs[i])\n",
        "#         print(all_labels[i])\n",
        "      \n",
        "\n",
        "# Note the lists above contain only the image names and\n",
        "# actual images are loaded and yielded below in batches\n",
        "# Below we prepare a batch of data points and yield the batch\n",
        "# In each batch we load \"batch_size\" number of image pairs\n",
        "# These images are then removed from the original set so that\n",
        "# they are not added again in the next batch.\n",
        "# batch_size = 256\n",
        "# k = 0\n",
        "# pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "# targets=np.zeros((batch_size,))\n",
        "# for ix, pair in enumerate(all_pairs):\n",
        "# #     img1 = cv2.imread(pair[0], 0)\n",
        "# #     img2 = cv2.imread(pair[1], 0)  \n",
        "#     print(pair[0])\n",
        "#     print(pair[1])"
      ],
      "metadata": {
        "id": "2LpnrW8A4EOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_labels)"
      ],
      "metadata": {
        "id": "MNmJ8s3-4ERM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_batch(orig_train, forg_train, 256)\n",
        "                              "
      ],
      "metadata": {
        "id": "Oz2hVUMQ4EUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_train[:10]"
      ],
      "metadata": {
        "id": "Au5NRyLR4EXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forg_train[:10]"
      ],
      "metadata": {
        "id": "r-EKts824EaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_val[:10]"
      ],
      "metadata": {
        "id": "gkHtylgP4EdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forg_val[:10]"
      ],
      "metadata": {
        "id": "IqUZaEEt3t30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orig_pairs = []\n",
        "        forg_pairs = []\n",
        "        gen_gen_labels = []\n",
        "        gen_for_labels = []\n",
        "        all_pairs = []\n",
        "        all_labels = []\n",
        "        \n",
        "        # Here we create pairs of Genuine-Genuine image names and Genuine-Forged image names\n",
        "        # For every person we have 24 genuine signatures, hence we have \n",
        "        # 24 choose 2 = 276 Genuine-Genuine image pairs for one person.\n",
        "        # To make Genuine-Forged pairs, we pair every Genuine signature of a person\n",
        "        # with 12 randomly sampled Forged signatures of the same person.\n",
        "        # Thus we make 24 * 12 = 300 Genuine-Forged image pairs for one person.\n",
        "        # In all we have 120 person's data in the training data.\n",
        "        # Total no. of Genuine-Genuine pairs = 120 * 276 = 33120\n",
        "        # Total number of Genuine-Forged pairs = 120 * 300 = 36000\n",
        "        # Total no. of data points = 33120 + 36000 = 69120\n",
        "        for orig, forg in zip(orig_groups, forg_groups):    \n",
        "            orig_pairs.extend(list(itertools.combinations(orig, 2)))\n",
        "            for i in orig:\n",
        "                for j in forg:\n",
        "                    forg_pairs.append((i,j))\n",
        "        \n",
        "\n",
        "        \n",
        "        # Label for Genuine-Genuine pairs is 1\n",
        "        # Label for Genuine-Forged pairs is 0\n",
        "        gen_gen_labels = [1]*len(orig_pairs)\n",
        "        gen_for_labels = [0]*len(forg_pairs)\n",
        "        \n",
        "        # Concatenate all the pairs together along with their labels and shuffle them\n",
        "        all_pairs = orig_pairs + forg_pairs\n",
        "        all_labels = gen_gen_labels + gen_for_labels\n",
        "        del orig_pairs, forg_pairs, gen_gen_labels, gen_for_labels\n",
        "        all_pairs, all_labels = shuffle(all_pairs, all_labels)\n",
        "        \n",
        "        # Note the lists above contain only the image names and\n",
        "        # actual images are loaded and yielded below in batches\n",
        "        # Below we prepare a batch of data points and yield the batch\n",
        "        # In each batch we load \"batch_size\" number of image pairs\n",
        "        # These images are then removed from the original set so that\n",
        "        # they are not added again in the next batch.\n",
        "            \n",
        "        k = 0\n",
        "        pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "        targets=np.zeros((batch_size,))\n",
        "        for ix, pair in enumerate(all_pairs):\n",
        "            img1 = cv2.imread(pair[0], 0)\n",
        "            img2 = cv2.imread(pair[1], 0)\n",
        "            img1 = cv2.resize(img1, (img_w, img_h))\n",
        "            img2 = cv2.resize(img2, (img_w, img_h))\n",
        "            \n",
        "            ret1,thresh1 = cv2.threshold(img1,200,255,cv2.THRESH_BINARY)\n",
        "            ret2,thresh2 = cv2.threshold(img2,200,255,cv2.THRESH_BINARY)\n",
        "            \n",
        "            img1 = np.array(thresh1, dtype = np.float64)\n",
        "            img2 = np.array(thresh2, dtype = np.float64)\n",
        "            \n",
        "            img1 /= 255\n",
        "            img2 /= 255\n",
        "            \n",
        "            img1 = img1[..., np.newaxis]\n",
        "            img2 = img2[..., np.newaxis]\n",
        "            pairs[0][k, :, :, :] = img1\n",
        "            pairs[1][k, :, :, :] = img2\n",
        "            \n",
        "            #print(pair[1])\n",
        "            targets[k] = all_labels[ix]\n",
        "            #print(targets[k])\n",
        "            #print(\"f{pair[0]}:{pair[1]}:{targets[k]}\")\n",
        "            k += 1\n",
        "            if k == batch_size:\n",
        "                yield pairs,targets\n",
        "                print(pairs)\n",
        "                print(targets)\n",
        "                k = 0\n",
        "                pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "                targets=np.zeros((batch_size,))"
      ],
      "metadata": {
        "id": "yWNLtxn-4Xwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zef=[]\n",
        "\n",
        "def generate_batch(orig_groups, forg_groups, batch_size = 256):\n",
        "    '''Function to generate a batch of data with batch_size number of data points\n",
        "    Half of the data points will be Genuine-Genuine pairs and half will be Genuine-Forged pairs'''\n",
        "    while True:\n",
        "        orig_pairs = []\n",
        "        forg_pairs = []\n",
        "        gen_gen_labels = []\n",
        "        gen_for_labels = []\n",
        "        all_pairs = []\n",
        "        all_labels = []\n",
        "        \n",
        "        # Here we create pairs of Genuine-Genuine image names and Genuine-Forged image names\n",
        "        # For every person we have 24 genuine signatures, hence we have \n",
        "        # 24 choose 2 = 276 Genuine-Genuine image pairs for one person.\n",
        "        # To make Genuine-Forged pairs, we pair every Genuine signature of a person\n",
        "        # with 12 randomly sampled Forged signatures of the same person.\n",
        "        # Thus we make 24 * 12 = 300 Genuine-Forged image pairs for one person.\n",
        "        # In all we have 120 person's data in the training data.\n",
        "        # Total no. of Genuine-Genuine pairs = 120 * 276 = 33120\n",
        "        # Total number of Genuine-Forged pairs = 120 * 300 = 36000\n",
        "        # Total no. of data points = 33120 + 36000 = 69120\n",
        "        for orig, forg in zip(orig_groups, forg_groups):    \n",
        "            orig_pairs.extend(list(itertools.combinations(orig, 2)))\n",
        "            for i in orig:\n",
        "                for j in forg:\n",
        "                    forg_pairs.append((i,j))\n",
        "        \n",
        "\n",
        "        \n",
        "        # Label for Genuine-Genuine pairs is 1\n",
        "        # Label for Genuine-Forged pairs is 0\n",
        "        gen_gen_labels = [1]*len(orig_pairs)\n",
        "        gen_for_labels = [0]*len(forg_pairs)\n",
        "        \n",
        "        # Concatenate all the pairs together along with their labels and shuffle them\n",
        "        all_pairs = orig_pairs + forg_pairs\n",
        "        all_labels = gen_gen_labels + gen_for_labels\n",
        "        del orig_pairs, forg_pairs, gen_gen_labels, gen_for_labels\n",
        "        all_pairs, all_labels = shuffle(all_pairs, all_labels)\n",
        "        \n",
        "        # Note the lists above contain only the image names and\n",
        "        # actual images are loaded and yielded below in batches\n",
        "        # Below we prepare a batch of data points and yield the batch\n",
        "        # In each batch we load \"batch_size\" number of image pairs\n",
        "        # These images are then removed from the original set so that\n",
        "        # they are not added again in the next batch.\n",
        "            \n",
        "        k = 0\n",
        "        pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "        targets=np.zeros((batch_size,))\n",
        "        for ix, pair in enumerate(all_pairs):\n",
        "            img1 = cv2.imread(pair[0], 0)\n",
        "            img2 = cv2.imread(pair[1], 0)\n",
        "            img1 = cv2.resize(img1, (img_w, img_h))\n",
        "            img2 = cv2.resize(img2, (img_w, img_h))\n",
        "            \n",
        "            ret1,thresh1 = cv2.threshold(img1,200,255,cv2.THRESH_BINARY)\n",
        "            ret2,thresh2 = cv2.threshold(img2,200,255,cv2.THRESH_BINARY)\n",
        "            \n",
        "            img1 = np.array(thresh1, dtype = np.float64)\n",
        "            img2 = np.array(thresh2, dtype = np.float64)\n",
        "            \n",
        "            img1 /= 255\n",
        "            img2 /= 255\n",
        "            \n",
        "            img1 = img1[..., np.newaxis]\n",
        "            img2 = img2[..., np.newaxis]\n",
        "            pairs[0][k, :, :, :] = img1\n",
        "            pairs[1][k, :, :, :] = img2\n",
        "            zef=pairs[0]\n",
        "            print(zef)\n",
        "            \n",
        "            #print(pair[1])\n",
        "            targets[k] = all_labels[ix]\n",
        "            k += 1\n",
        "            if k == batch_size:\n",
        "                # pairs,targets\n",
        "                print(pairs)\n",
        "                print(targets)\n",
        "#                 print(\"-----------------------\")\n",
        "                k = 0\n",
        "                pairs=[np.zeros((batch_size, img_h, img_w, 1)) for i in range(2)]\n",
        "                targets=np.zeros((batch_size,))\n",
        "                \n",
        "                \n",
        "\n",
        "                \n",
        "# def euclidean_distance(vects):\n",
        "#     '''Compute Euclidean Distance between two vectors'''\n",
        "#     x, y = vects\n",
        "#     return K.sqrt(K.sum(K.square(x - y), axis=1, keepdims=True))\n",
        "def euclidean_distance(vects):\n",
        "    \"\"\"Find the Euclidean distance between two vectors.\n",
        "\n",
        "    Arguments:\n",
        "        vects: List containing two tensors of same length.\n",
        "\n",
        "    Returns:\n",
        "        Tensor containing euclidean distance\n",
        "        (as floating point value) between vectors.\n",
        "    \"\"\"\n",
        "\n",
        "    x, y = vects\n",
        "    sum_square = tf.math.reduce_sum(tf.math.square(x - y), axis=1, keepdims=True)\n",
        "    return tf.math.sqrt(tf.math.maximum(sum_square, tf.keras.backend.epsilon()))\n",
        "\n",
        "def manhattan_distance(vects):\n",
        "    \"\"\"Find the Euclidean distance between two vectors.\n",
        "\n",
        "    Arguments:\n",
        "        vects: List containing two tensors of same length.\n",
        "\n",
        "    Returns:\n",
        "        Tensor containing euclidean distance\n",
        "        (as floating point value) between vectors.\n",
        "    \"\"\"\n",
        "\n",
        "    x, y = vects\n",
        "    m_sum = tf.math.reduce_sum(abs(x - y), axis=1, keepdims=True)\n",
        "    return tf.math.maximum(m_sum, tf.keras.backend.epsilon())\n",
        "\n",
        "\n",
        "\n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def loss(margin=1):\n",
        "    \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
        "\n",
        "    Arguments:\n",
        "        margin: Integer, defines the baseline for distance for which pairs\n",
        "                should be classified as dissimilar. - (default is 1).\n",
        "\n",
        "    Returns:\n",
        "        'constrastive_loss' function with data ('margin') attached.\n",
        "    \"\"\"\n",
        "\n",
        "    # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
        "    #                         true_value * square( max(margin-prediction, 0) ))\n",
        "    def contrastive_loss(y_true, y_pred):\n",
        "        \"\"\"Calculates the constrastive loss.\n",
        "\n",
        "        Arguments:\n",
        "            y_true: List of labels, each label is of type float32.\n",
        "            y_pred: List of predictions of same length as of y_true,\n",
        "                    each label is of type float32.\n",
        "\n",
        "        Returns:\n",
        "            A tensor containing constrastive loss as floating point value.\n",
        "        \"\"\"\n",
        "\n",
        "        square_pred = tf.math.square(y_pred)\n",
        "        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
        "        return tf.math.reduce_mean(\n",
        "            (1 - y_true) * square_pred + (y_true) * margin_square\n",
        "        )\n",
        "\n",
        "    return contrastive_loss\n",
        "\n",
        "\n",
        "def BinaryCrossEntropy(y_true, y_pred):\n",
        "    y_pred = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "    term_0 = (1-y_true) * np.log(1-y_pred + 1e-7)\n",
        "    term_1 = y_true * np.log(y_pred + 1e-7)\n",
        "    return -np.mean(term_0+term_1, axis=0)\n",
        "\n",
        "\n",
        "\n",
        "# def loss1(margin=1):\n",
        "#     \"\"\"Provides 'constrastive_loss' an enclosing scope with variable 'margin'.\n",
        "\n",
        "#     Arguments:\n",
        "#         margin: Integer, defines the baseline for distance for which pairs\n",
        "#                 should be classified as dissimilar. - (default is 1).\n",
        "\n",
        "#     Returns:\n",
        "#         'constrastive_loss' function with data ('margin') attached.\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Contrastive loss = mean( (1-true_value) * square(prediction) +\n",
        "#     #                         true_value * square( max(margin-prediction, 0) ))\n",
        "#     def BinaryCrossEntropy(y_true, y_pred):\n",
        "#         \"\"\"Calculates the constrastive loss.\n",
        "\n",
        "#         Arguments:\n",
        "#             y_true: List of labels, each label is of type float32.\n",
        "#             y_pred: List of predictions of same length as of y_true,\n",
        "#                     each label is of type float32.\n",
        "\n",
        "#         Returns:\n",
        "#             A tensor containing constrastive loss as floating point value.\n",
        "#         \"\"\"\n",
        "\n",
        "#         square_pred = tf.math.square(y_pred)\n",
        "#         margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))\n",
        "#         return tf.math.reduce_mean(\n",
        "#             (1 - y_true) * square_pred + (y_true) * margin_square\n",
        "#         )\n",
        "\n",
        "#     return contrastive_loss\n",
        "\n",
        "\n",
        "\n",
        "input_shape=(img_h, img_w, 1)"
      ],
      "metadata": {
        "id": "UgMgAYon4Xzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_batch(orig_val, forg_val, batch_size = 256)"
      ],
      "metadata": {
        "id": "H_lEqpni4X2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def signet2021(inputs):\n",
        "#     '''Siamese Network with inception network'''\n",
        "\n",
        "    \n",
        "#     l_11 = Conv2D(32, kernel_size=(7, 7), activation='relu', strides=1,kernel_initializer='glorot_uniform', data_format='channels_last', padding = 'valid')(inputs)\n",
        "#     l_12 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "#     l_13 = MaxPooling2D((2,2), strides=(2, 2))\n",
        "#     l_14 = ZeroPadding2D((2, 2), data_format='channels_last')\n",
        "    \n",
        "    \n",
        "    \n",
        "#     l_2 = MaxPooling2D((3,3), strides=(2, 2))\n",
        "    \n",
        "    \n",
        "#     l_31 = Conv2D(32, kernel_size=(1, 1), activation='relu', strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "#     l_32 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "#     l_33 = MaxPooling2D((2,2), strides=(2, 2))\n",
        "#     l_34 = ZeroPadding2D((2, 2), data_format='channels_last')\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "#     l_41 = Conv2D(32, kernel_size=(3, 3), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "#     l_42 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "#     l_43 = MaxPooling2D((2,2), strides=(2, 2))\n",
        "#     l_44 = ZeroPadding2D((2, 2), data_format='channels_last')\n",
        "    \n",
        "    \n",
        "#     l_5 = MaxPooling2D((3,3), strides=(2, 2))\n",
        "    \n",
        "    \n",
        "    \n",
        "#     y_ = l_5(l_44(l_43(l_42(l_41(l_34(l_33(l_32(l_31(l_2(l_14(l_13(l_12(l_11)))))))))))))\n",
        "    \n",
        "#     x = y_\n",
        "    \n",
        "    \n",
        "#     ######### Create Inception Network starts ##########\n",
        "    \n",
        "#     ### kernal_size = (1,1)\n",
        "#     layer_1 = Conv2D(32, kernel_size=(7, 7), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "#     layer_12 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "#     layer_13 = MaxPooling2D((2,2), strides=(2, 2), padding='same')\n",
        "#     y_1 = layer_13(layer_12(layer_1(x)))\n",
        "    \n",
        "\n",
        "\n",
        "    \n",
        "    \n",
        "#     layer_21_1 = Conv2D(32, kernel_size=(1, 1), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "#     layer_22_1 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "#     layer_23_1 = MaxPooling2D((2,2), strides=(2, 2), padding='same')\n",
        "    \n",
        "    \n",
        "#     layer_21_2 = Conv2D(32, kernel_size=(3, 3), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "#     layer_22_2 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "#     layer_23_2 = MaxPooling2D((2,2), strides=(2, 2), padding='same')\n",
        "      \n",
        "#     y_2 = layer_23_2(layer_22_2(layer_21_2(layer_23_1(layer_22_1(layer_21_1(x))))))\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "#     layer_31_1 = Conv2D(32, kernel_size=(1, 1), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "#     layer_32_1 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "#     layer_33_1 = MaxPooling2D((2,2), strides=(2, 2), padding='same')\n",
        "    \n",
        "#     ### kernal_size = (5,5)\n",
        "#     layer_31_2 = Conv2D(32, kernel_size=(3, 3), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "#     layer_32_2 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "#     layer_33_2 = MaxPooling2D((2,2), strides=(2, 2), padding='same')\n",
        "    \n",
        "#     y_3 = layer_33_2(layer_32_2(layer_31_2(layer_33_1(layer_32_1(layer_31_1(x))))))\n",
        "\n",
        "    \n",
        "    \n",
        "#     layer_41 = MaxPooling2D((3,3), strides=(2, 2), padding='same')\n",
        "#     ### kernal_size = (5,5)\n",
        "#     layer_42 = Conv2D(32, kernel_size=(3, 3), activation='relu', strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "#     layer_43 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "#     layer_44 = MaxPooling2D((2,2), strides=(2, 2), padding='same')\n",
        "    \n",
        "#     y_4 = layer_44(layer_43(layer_42(layer_41(x))))\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "#     concatted = tf.keras.layers.Concatenate()([y_1, y_2, y_3, y_4])\n",
        "    \n",
        "    \n",
        "#     #### inception layer ends ########\n",
        "    \n",
        "    \n",
        "#     l_31 = AveragePooling2D(pool_size=(1, 1),strides=(2, 2), padding='valid')\n",
        "    \n",
        "#     l_32 = Dense(500, bias_regularizer=l2(0.0005), activation='relu', kernel_initializer='glorot_uniform')\n",
        "    \n",
        "    \n",
        "#     y = l_32(l_31(concatted))\n",
        "    \n",
        "#     return y"
      ],
      "metadata": {
        "id": "tsDEuz1R4X5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def signet2021(inputs):\n",
        "    '''Siamese Network with inception network'''\n",
        "\n",
        "    \n",
        "    l_11 = Conv2D(32, kernel_size=(7, 7), activation='relu', strides=1,kernel_initializer='glorot_uniform', data_format='channels_last', padding = 'valid')(inputs)\n",
        "    l_12 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "    l_13 = MaxPooling2D((2,2), strides=(2, 2))\n",
        "    l_14 = ZeroPadding2D((2, 2), data_format='channels_last')\n",
        "    \n",
        "    \n",
        "    \n",
        "    l_2 = MaxPooling2D((3,3), strides=(2, 2))\n",
        "    \n",
        "    \n",
        "    l_31 = Conv2D(32, kernel_size=(1, 1), activation='relu', strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "    l_32 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "    l_33 = MaxPooling2D((2,2), strides=(2, 2))\n",
        "    l_34 = ZeroPadding2D((2, 2), data_format='channels_last')\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    l_41 = Conv2D(32, kernel_size=(3, 3), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "    l_42 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "    l_43 = MaxPooling2D((2,2), strides=(2, 2))\n",
        "    l_44 = ZeroPadding2D((2, 2), data_format='channels_last')\n",
        "    \n",
        "    \n",
        "    l_5 = MaxPooling2D((3,3), strides=(2, 2))\n",
        "    \n",
        "    \n",
        "    \n",
        "    y_ = l_5(l_44(l_43(l_42(l_41(l_34(l_33(l_32(l_31(l_2(l_14(l_13(l_12(l_11)))))))))))))\n",
        "    \n",
        "    x = y_\n",
        "    \n",
        "    \n",
        "    ######### Create Inception Network starts ##########\n",
        "    \n",
        "    ### kernal_size = (1,1)\n",
        "    layer_1 = Conv2D(32, kernel_size=(1, 1), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "    layer_12 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "    layer_13 = MaxPooling2D((2,2), strides=(2, 2), padding='same')\n",
        "    y_1 = layer_13(layer_12(layer_1(x)))\n",
        "    y_1 = resize(y_1, [4,4], method='bilinear')\n",
        "\n",
        "    \n",
        "    \n",
        "    layer_21_1 = Conv2D(32, kernel_size=(1, 1), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "    layer_22_1 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "    layer_23_1 = MaxPooling2D((2,2), strides=(2, 2), padding='same')\n",
        "    \n",
        "    \n",
        "    layer_21_2 = Conv2D(32, kernel_size=(3, 3), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "    layer_22_2 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "    layer_23_2 = MaxPooling2D((2,2), strides=(2, 2), padding='same')\n",
        "      \n",
        "    y_2 = layer_23_2(layer_22_2(layer_21_2(layer_23_1(layer_22_1(layer_21_1(x))))))\n",
        "    y_2 = resize(y_2, [4,4], method='bilinear')\n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    layer_31_1 = Conv2D(32, kernel_size=(1, 1), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "    layer_32_1 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "    layer_33_1 = MaxPooling2D((2,2), strides=(1, 1), padding='same')\n",
        "    \n",
        "    ### kernal_size = (5,5)\n",
        "    layer_31_2 = Conv2D(32, kernel_size=(5, 5), activation='relu',  strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "    layer_32_2 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "    layer_33_2 = MaxPooling2D((2,2), strides=(2, 2), padding='same')\n",
        "    \n",
        "    y_3 = layer_33_2(layer_32_2(layer_31_2(layer_33_1(layer_32_1(layer_31_1(x))))))\n",
        "    y_3 = resize(y_3, [4,4], method='bilinear')\n",
        "\n",
        "    \n",
        "    \n",
        "    layer_41 = MaxPooling2D((3,3), strides=(1, 1), padding='same')\n",
        "    ### kernal_size = (5,5)\n",
        "    layer_42 = Conv2D(32, kernel_size=(5, 5), activation='relu', strides=1, kernel_initializer='glorot_uniform', data_format='channels_last',padding = 'valid')\n",
        "    layer_43 = BatchNormalization(epsilon=1e-06, axis=1, momentum=0.9)\n",
        "    layer_44 = MaxPooling2D((2,2), strides=(1,1), padding='same')\n",
        "    \n",
        "    y_4 = layer_44(layer_43(layer_42(layer_41(x))))\n",
        "    y_4 = resize(y_4, [4,4], method='bilinear')\n",
        "\n",
        "    \n",
        "    \n",
        "    \n",
        "    concatted = tf.keras.layers.Concatenate()([ y_1, y_2, y_3, y_4 ])\n",
        "    \n",
        "    \n",
        "    #### inception layer ends ########\n",
        "    \n",
        "    \n",
        "    l_31 = AveragePooling2D(pool_size=(1, 1),strides=(2, 2), padding='valid')\n",
        "    \n",
        "    l_32 = Dense(500, bias_regularizer=l2(0.0005), activation='relu', kernel_initializer='glorot_uniform')\n",
        "    \n",
        "    \n",
        "    y = l_32(l_31(concatted))\n",
        "    \n",
        "    return y\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# network definition\n",
        "# base_network = signet2021(inputs)\n",
        "\n",
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        "\n",
        "# because we re-use the same instance `base_network`,\n",
        "# the weights of the network\n",
        "# will be shared across the two branches\n",
        "processed_a = signet2021(input_a)\n",
        "processed_b = signet2021(input_b)\n",
        "print(processed_a)\n",
        "print(processed_b)\n",
        "# Compute the Euclidean distance between the two vectors in the latent space\n",
        "# from sklearn.metrics.pairwise import manhattan_distances\n",
        "# distance = manhattan_distances([processed_a], [processed_b])\n",
        "\n",
        "# distance = Lambda(euclidean_distance, output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
        "# print(distance)\n",
        "\n",
        "\n",
        "merge_layer = Lambda(manhattan_distance)([processed_a, processed_b])\n",
        "normal_layer = BatchNormalization()(merge_layer)\n",
        "output_layer = Dense(1, activation=\"sigmoid\")(normal_layer)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "margin = 1\n",
        "model = Model([input_a, input_b], output_layer)\n",
        "model.summary()\n",
        "\n",
        "# model = Model([input_a, input_b],distance)"
      ],
      "metadata": {
        "id": "8lMPS8yu4X8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sz = 256\n",
        "num_train_samples = 276*40 + 576*40\n",
        "num_val_samples = 276*10 + 576*10\n",
        "num_test_samples = 276*5 + 576*5\n",
        "\n",
        "# devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "# print(devices[0])\n",
        "# # n_gpus=1\n",
        "\n",
        "# # device_type = ‘GPU’\n",
        "\n",
        "# devices = tf.config.experimental.list_physical_devices(\n",
        "#           device_type)\n",
        "\n",
        "# devices_names = [d.name.split(“e:”)[1] for d in devices]\n",
        "\n",
        "# strategy = tf.distribute.MirroredStrategy(\n",
        "#            devices=devices_names[:n_gpus])\n",
        "\n",
        "# with strategy.scope():\n",
        "#     model = Model([input_a, input_b], output_layer)\n",
        "#     tb_callback = [\n",
        "#     EarlyStopping(patience=12, verbose=1),\n",
        "#     ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.0002, verbose=1),\n",
        "#     ModelCheckpoint('./Weights/signet2021-bhsig260-{epoch:03d}.h5', verbose=1, save_weights_only=True)\n",
        "#     ]\n",
        "\n",
        "\n",
        "#     # compile model using RMSProp Optimizer and Contrastive loss function defined above\n",
        "#     rms = RMSprop(learning_rate=0.0002, rho=0.9, epsilon=1e-08)\n",
        "#     model.compile(loss=loss(margin=margin),optimizer=rms,  metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "GYoEspfC4X_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "2I-l1dSw4YB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_available = tf.test.is_gpu_available()\n",
        "print(gpu_available)"
      ],
      "metadata": {
        "id": "WGUN-Ndq4YE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "-mwjOGBz3t6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# margin = 1\n",
        "model.compile(loss=loss(margin=margin), optimizer=\"RMSprop\", metrics=[\"accuracy\"])\n",
        "\n",
        "# num_train_samples, num_val_samples, num_test_samples\n",
        "# model.summary()\n",
        "\n",
        "\n",
        "# Using Keras Callbacks, save the model after every epoch\n",
        "# Reduce the learning rate by a factor of 0.1 if the validation loss does not improve for 5 epochs\n",
        "# Stop the training using early stopping if the validation loss does not improve for 12 epochs\n",
        "\n",
        "root_logdir = os.path.join(os.curdir,\"my_logs\")\n",
        "\n",
        "def get_run_logdir():\n",
        "    import time\n",
        "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "    return os.path.join(root_logdir,run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
        "\n",
        "# model call backs\n",
        "\n",
        "tb_callback = TensorBoard(log_dir=\"/Users/jitendra/signature_verification/model_callback\", histogram_freq=0, write_graph=True, write_images=True)\n",
        "\n",
        "#model training\n",
        "results = model.fit_generator(generate_batch(orig_train, forg_train, batch_sz),\n",
        "                              steps_per_epoch = num_train_samples//batch_sz,\n",
        "                              epochs = 1,\n",
        "                              validation_data = generate_batch(orig_val, forg_val, batch_sz),\n",
        "                              validation_steps = num_val_samples//batch_sz,\n",
        "                              callbacks = [tb_callback, tensorboard_cb])\n",
        "\n",
        "\n",
        "\n",
        "# save model and its weights\n",
        "# model.save(\"Weights/signature_verification_model21\")\n",
        "# model.save_weights('Weights/signature_verification_model21.h5')\n",
        "\n",
        "\n",
        "def plt_metric(results, metric, title, has_valid=True):\n",
        "    \"\"\"Plots the given 'metric' from 'history'.\n",
        "\n",
        "    Arguments:\n",
        "        history: history attribute of History object returned from Model.fit.\n",
        "        metric: Metric to plot, a string value present as key in 'history'.\n",
        "        title: A string to be used as title of plot.\n",
        "        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    plt.plot(results[metric])\n",
        "    if has_valid:\n",
        "        plt.plot(results[\"val_\" + metric])\n",
        "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Plot the accuracy\n",
        "plt_metric(history=hresults.history, metric=\"accuracy\", title=\"Model accuracy\")\n",
        "\n",
        "# Plot the constrastive loss\n",
        "plt_metric(history=results.history, metric=\"loss\", title=\"Constrastive Loss\")"
      ],
      "metadata": {
        "id": "rcr_YBIG3t88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plt_metric(results, metric, title, has_valid=True):\n",
        "    \"\"\"Plots the given 'metric' from 'history'.\n",
        "\n",
        "    Arguments:\n",
        "        history: history attribute of History object returned from Model.fit.\n",
        "        metric: Metric to plot, a string value present as key in 'history'.\n",
        "        title: A string to be used as title of plot.\n",
        "        has_valid: Boolean, true if valid data was passed to Model.fit else false.\n",
        "\n",
        "    Returns:\n",
        "        None.\n",
        "    \"\"\"\n",
        "    plt.plot(results[metric])\n",
        "    if has_valid:\n",
        "        plt.plot(results[\"val_\" + metric])\n",
        "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.title(title)\n",
        "    plt.ylabel(metric)\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Plot the accuracy\n",
        "plt_metric(results.history, metric=\"accuracy\", title=\"Model accuracy\")\n",
        "\n",
        "# Plot the constrastive loss\n",
        "plt_metric(results.history, metric=\"loss\", title=\"Constrastive Loss\")"
      ],
      "metadata": {
        "id": "VRKmrHIM3t_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy_roc(predictions, labels):\n",
        "    '''Compute ROC accuracy with a range of thresholds on distances.\n",
        "    '''\n",
        "    dmax = np.max(predictions)\n",
        "    dmin = np.min(predictions)\n",
        "    nsame = np.sum(labels == 1)\n",
        "    ndiff = np.sum(labels == 0)\n",
        "   \n",
        "    step = 0.01\n",
        "    max_acc = 0\n",
        "    best_thresh = -1\n",
        "   \n",
        "    for d in np.arange(dmin, dmax+step, step):\n",
        "        idx1 = predictions.ravel() <= d\n",
        "        idx2 = predictions.ravel() > d\n",
        "       \n",
        "        tpr = float(np.sum(labels[idx1] == 1)) / nsame       \n",
        "        tnr = float(np.sum(labels[idx2] == 0)) / ndiff\n",
        "        acc = 0.5 * (tpr + tnr)       \n",
        "#       print ('ROC', acc, tpr, tnr)\n",
        "       \n",
        "        if (acc > max_acc):\n",
        "            max_acc, best_thresh = acc, d\n",
        "           \n",
        "    return max_acc, best_thresh"
      ],
      "metadata": {
        "id": "Gt_h2tQs44dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "AyLdt-vb44gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "id": "q7g9ZC8a44j0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nano requirements.txt\n"
      ],
      "metadata": {
        "id": "I3fhpsdY44ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_gen = generate_batch(orig_test, forg_test, 1)\n",
        "pred, tr_y = [], []\n",
        "for i in range(num_test_samples):\n",
        "    (img1, img2), label = next(test_gen)\n",
        "    tr_y.append(label)\n",
        "    pred.append(model.predict([img1, img2])[0][0])"
      ],
      "metadata": {
        "id": "RwDFQhOm44p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_acc, threshold = compute_accuracy_roc(np.array(pred), np.array(tr_y))\n",
        "tr_acc, threshold"
      ],
      "metadata": {
        "id": "Cw_thmLv5GRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_score():\n",
        "    '''Predict distance score and classify test images as Genuine or Forged'''\n",
        "    test_point, test_label = next(test_gen)\n",
        "    img1, img2 = test_point[0], test_point[1]\n",
        "    \n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 10))\n",
        "    ax1.imshow(np.squeeze(img1), cmap='gray')\n",
        "    ax2.imshow(np.squeeze(img2), cmap='gray')\n",
        "    ax1.set_title('Genuine')\n",
        "    if test_label == 1:\n",
        "        ax2.set_title('Genuine')\n",
        "    else:\n",
        "        ax2.set_title('Forged')\n",
        "    ax1.axis('off')\n",
        "    ax2.axis('off')\n",
        "    plt.show()\n",
        "    result = model.predict([img1, img2])\n",
        "    diff = result[0][0]\n",
        "    print(\"Difference Score = \", diff)\n",
        "    if diff > threshold:\n",
        "        print(\"Its a Forged Signature\")\n",
        "    else:\n",
        "        print(\"Its a Genuine Signature\")"
      ],
      "metadata": {
        "id": "j-HQEYr_5GUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_score()"
      ],
      "metadata": {
        "id": "K4Sog-B65GXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_score()"
      ],
      "metadata": {
        "id": "pCZ97lnA5GaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_score()"
      ],
      "metadata": {
        "id": "OGKZ9OV35Gc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TIHzjl_S5GgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k7Lm4hnS44tG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DL_JJdQO3uCk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}